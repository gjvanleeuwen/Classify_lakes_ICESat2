import matplotlib.pyplot as plt
import seaborn as sns

def plot_confusion_matrix(cm_array, class_name_list,
                          normalized=True, cmap='bone', outpath=None):
    """
    Function to plot confusion matrix array as generated by classifier model, if outpath will write plot to disk

    Parameters
    ----------
    cm_array : np.array
        2d array as output from model_selection.confusion matrix or xgb.confusion_matrix
    class_name_list : list
        list of strings with names for all classes in the 2d array
    normalized : bool, optional
        if True will scale color scheme to total samples of the class
    cmap : str, optional
        string defining color schemes for sns.heatmap
    outpath : str, optional
        If not None will save figure to this local path

    """
    plt.figure(figsize=[7, 6])
    norm_cm = cm_array
    if normalized:
        norm_cm = cm_array.astype('float') / cm_array.sum(axis=1)[:, np.newaxis]
    sns.heatmap(norm_cm, annot=cm_array, fmt='g', xticklabels=class_name_list, yticklabels=class_name_list, cmap=cmap)
    if outpath is not None:
        plt.savefig(outpath)


def plot_feature_importance(importances_array, bands_to_use, outpath=None):
    """
    Function to plot importances as generated by classifier model

    Parameters
    ----------
    importances : np.array
        importances for every feature as generated by xgb or sklearn
    outpath : str, optional
        If not None will save figure to this local path

    """
    indices = np.argsort(importances_array)[::-1]
    len_features = len(importances_array)

    utl.log("Feature ranking:", log_level='INFO')
    for f in range(len_features):
        utl.log("%d. feature %d (%f)" % (f + 1, indices[f], importances_array[indices[f]]), log_level='INFO')

    plt.figure()
    plt.title("Feature importances")
    plt.bar(bands_to_use, importances_array[indices], color="r",)
    plt.xticks(range(len_features), indices)
    plt.xlim([-1, len_features])
    if outpath is not None:
        plt.savefig(outpath)


def plot_cm_and_importances(label_int_list, results, class_name_list, model, bands_to_use,
                           classifier='sklearn'):
    """
    Function to plot both feature importance and confusion matrix for a trained model and results vs true values
    Parameters
    ----------
    label_int_list : list
        list of ints referring to correct class for each row of training array
    results : np.array
        1d array holding all predicted classes for each row (preferably cross validated)
    class_name_list : list
        list of strings for every vegtype/landclass label to be classified
    model : RandomForestClassifier or xgb.XGBClassifier
        trained model to extract importances from
    classifier : str, optional
        indicates type of classifier used and therefore determines usable metrics, standard is sklearn

    Returns
    -------
    prints classification report with accuracy for each class
    """
    cm = metrics.confusion_matrix(label_int_list, results, normalize=True)
    plot_confusion_matrix(cm, class_name_list, normalized=True)
    if classifier == 'xgboost':
        xgb.plot_importance(model)
    if classifier == 'sklearn':
        importances = model.feature_importances_
        plot_feature_importance(importances, bands_to_use)
    plt.show()
    return utl.log((metrics.classification_report(label_int_list, results)), log_level='INFO')